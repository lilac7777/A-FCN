name: "ResNet-50"
layer {
  name: 'data'
  type: 'Python'
  top: 'data'
  top: 'rois'
  top: 'labels'
  top: 'bbox_targets'
  top: 'bbox_inside_weights'
  top: 'bbox_outside_weights'
  top: 'Sig_rfcn_mask_label'
  top: 'foreverone'

  python_param {
    module: 'roi_data_layer.layer'
    layer: 'RoIDataLayer'
    param_str: "'num_classes': 21"
  }
}

# ------------------------ conv1 -----------------------------
layer {
    bottom: "data"
    top: "conv1"
    name: "conv1"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 7
        pad: 3
        stride: 2
    }
    param {
        lr_mult: 0.0
    }
    param {
        lr_mult: 0.0
    }
    
}

layer {
    bottom: "conv1"
    top: "conv1"
    name: "bn_conv1"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "conv1"
    top: "conv1"
    name: "scale_conv1"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "conv1"
    top: "conv1"
    name: "conv1_relu"
    type: "ReLU"
}

layer {
    bottom: "conv1"
    top: "pool1"
    name: "pool1"
    type: "Pooling"
    pooling_param {
        kernel_size: 3
        stride: 2
        pool: MAX
    }
}

layer {
    bottom: "pool1"
    top: "res2a_branch1"
    name: "res2a_branch1"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 0.0
    }
}

layer {
    bottom: "res2a_branch1"
    top: "res2a_branch1"
    name: "bn2a_branch1"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res2a_branch1"
    top: "res2a_branch1"
    name: "scale2a_branch1"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "pool1"
    top: "res2a_branch2a"
    name: "res2a_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 0.0
    }
}

layer {
    bottom: "res2a_branch2a"
    top: "res2a_branch2a"
    name: "bn2a_branch2a"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res2a_branch2a"
    top: "res2a_branch2a"
    name: "scale2a_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res2a_branch2a"
    top: "res2a_branch2a"
    name: "res2a_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res2a_branch2a"
    top: "res2a_branch2b"
    name: "res2a_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 3
        pad: 1
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 0.0
    }
}

layer {
    bottom: "res2a_branch2b"
    top: "res2a_branch2b"
    name: "bn2a_branch2b"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res2a_branch2b"
    top: "res2a_branch2b"
    name: "scale2a_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res2a_branch2b"
    top: "res2a_branch2b"
    name: "res2a_branch2b_relu"
    type: "ReLU"
}

layer {
    bottom: "res2a_branch2b"
    top: "res2a_branch2c"
    name: "res2a_branch2c"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 0.0
    }
}

layer {
    bottom: "res2a_branch2c"
    top: "res2a_branch2c"
    name: "bn2a_branch2c"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res2a_branch2c"
    top: "res2a_branch2c"
    name: "scale2a_branch2c"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res2a_branch1"
    bottom: "res2a_branch2c"
    top: "res2a"
    name: "res2a"
    type: "Eltwise"
}

layer {
    bottom: "res2a"
    top: "res2a"
    name: "res2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res2a"
    top: "res2b_branch2a"
    name: "res2b_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 0.0
    }
}

layer {
    bottom: "res2b_branch2a"
    top: "res2b_branch2a"
    name: "bn2b_branch2a"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res2b_branch2a"
    top: "res2b_branch2a"
    name: "scale2b_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res2b_branch2a"
    top: "res2b_branch2a"
    name: "res2b_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res2b_branch2a"
    top: "res2b_branch2b"
    name: "res2b_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 3
        pad: 1
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 0.0
    }
}

layer {
    bottom: "res2b_branch2b"
    top: "res2b_branch2b"
    name: "bn2b_branch2b"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res2b_branch2b"
    top: "res2b_branch2b"
    name: "scale2b_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res2b_branch2b"
    top: "res2b_branch2b"
    name: "res2b_branch2b_relu"
    type: "ReLU"
}

layer {
    bottom: "res2b_branch2b"
    top: "res2b_branch2c"
    name: "res2b_branch2c"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 0.0
    }
}

layer {
    bottom: "res2b_branch2c"
    top: "res2b_branch2c"
    name: "bn2b_branch2c"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res2b_branch2c"
    top: "res2b_branch2c"
    name: "scale2b_branch2c"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res2a"
    bottom: "res2b_branch2c"
    top: "res2b"
    name: "res2b"
    type: "Eltwise"
}

layer {
    bottom: "res2b"
    top: "res2b"
    name: "res2b_relu"
    type: "ReLU"
}

layer {
    bottom: "res2b"
    top: "res2c_branch2a"
    name: "res2c_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 0.0
    }
}

layer {
    bottom: "res2c_branch2a"
    top: "res2c_branch2a"
    name: "bn2c_branch2a"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res2c_branch2a"
    top: "res2c_branch2a"
    name: "scale2c_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res2c_branch2a"
    top: "res2c_branch2a"
    name: "res2c_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res2c_branch2a"
    top: "res2c_branch2b"
    name: "res2c_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 3
        pad: 1
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 0.0
    }
}

layer {
    bottom: "res2c_branch2b"
    top: "res2c_branch2b"
    name: "bn2c_branch2b"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res2c_branch2b"
    top: "res2c_branch2b"
    name: "scale2c_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res2c_branch2b"
    top: "res2c_branch2b"
    name: "res2c_branch2b_relu"
    type: "ReLU"
}

layer {
    bottom: "res2c_branch2b"
    top: "res2c_branch2c"
    name: "res2c_branch2c"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 0.0
    }
}

layer {
    bottom: "res2c_branch2c"
    top: "res2c_branch2c"
    name: "bn2c_branch2c"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res2c_branch2c"
    top: "res2c_branch2c"
    name: "scale2c_branch2c"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res2b"
    bottom: "res2c_branch2c"
    top: "res2c"
    name: "res2c"
    type: "Eltwise"
}

layer {
    bottom: "res2c"
    top: "res2c"
    name: "res2c_relu"
    type: "ReLU"
}

layer {
    bottom: "res2c"
    top: "res3a_branch1"
    name: "res3a_branch1"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 1
        pad: 0
        stride: 2
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res3a_branch1"
    top: "res3a_branch1"
    name: "bn3a_branch1"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res3a_branch1"
    top: "res3a_branch1"
    name: "scale3a_branch1"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res2c"
    top: "res3a_branch2a"
    name: "res3a_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 128
        kernel_size: 1
        pad: 0
        stride: 2
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res3a_branch2a"
    top: "res3a_branch2a"
    name: "bn3a_branch2a"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res3a_branch2a"
    top: "res3a_branch2a"
    name: "scale3a_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res3a_branch2a"
    top: "res3a_branch2a"
    name: "res3a_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res3a_branch2a"
    top: "res3a_branch2b"
    name: "res3a_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 128
        kernel_size: 3
        pad: 1
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res3a_branch2b"
    top: "res3a_branch2b"
    name: "bn3a_branch2b"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res3a_branch2b"
    top: "res3a_branch2b"
    name: "scale3a_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res3a_branch2b"
    top: "res3a_branch2b"
    name: "res3a_branch2b_relu"
    type: "ReLU"
}

layer {
    bottom: "res3a_branch2b"
    top: "res3a_branch2c"
    name: "res3a_branch2c"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res3a_branch2c"
    top: "res3a_branch2c"
    name: "bn3a_branch2c"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res3a_branch2c"
    top: "res3a_branch2c"
    name: "scale3a_branch2c"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res3a_branch1"
    bottom: "res3a_branch2c"
    top: "res3a"
    name: "res3a"
    type: "Eltwise"
}

layer {
    bottom: "res3a"
    top: "res3a"
    name: "res3a_relu"
    type: "ReLU"
}

layer {
    bottom: "res3a"
    top: "res3b_branch2a"
    name: "res3b_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 128
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res3b_branch2a"
    top: "res3b_branch2a"
    name: "bn3b_branch2a"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res3b_branch2a"
    top: "res3b_branch2a"
    name: "scale3b_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res3b_branch2a"
    top: "res3b_branch2a"
    name: "res3b_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res3b_branch2a"
    top: "res3b_branch2b"
    name: "res3b_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 128
        kernel_size: 3
        pad: 1
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res3b_branch2b"
    top: "res3b_branch2b"
    name: "bn3b_branch2b"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res3b_branch2b"
    top: "res3b_branch2b"
    name: "scale3b_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res3b_branch2b"
    top: "res3b_branch2b"
    name: "res3b_branch2b_relu"
    type: "ReLU"
}

layer {
    bottom: "res3b_branch2b"
    top: "res3b_branch2c"
    name: "res3b_branch2c"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res3b_branch2c"
    top: "res3b_branch2c"
    name: "bn3b_branch2c"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res3b_branch2c"
    top: "res3b_branch2c"
    name: "scale3b_branch2c"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res3a"
    bottom: "res3b_branch2c"
    top: "res3b"
    name: "res3b"
    type: "Eltwise"
}

layer {
    bottom: "res3b"
    top: "res3b"
    name: "res3b_relu"
    type: "ReLU"
}

layer {
    bottom: "res3b"
    top: "res3c_branch2a"
    name: "res3c_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 128
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res3c_branch2a"
    top: "res3c_branch2a"
    name: "bn3c_branch2a"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res3c_branch2a"
    top: "res3c_branch2a"
    name: "scale3c_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res3c_branch2a"
    top: "res3c_branch2a"
    name: "res3c_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res3c_branch2a"
    top: "res3c_branch2b"
    name: "res3c_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 128
        kernel_size: 3
        pad: 1
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res3c_branch2b"
    top: "res3c_branch2b"
    name: "bn3c_branch2b"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res3c_branch2b"
    top: "res3c_branch2b"
    name: "scale3c_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res3c_branch2b"
    top: "res3c_branch2b"
    name: "res3c_branch2b_relu"
    type: "ReLU"
}

layer {
    bottom: "res3c_branch2b"
    top: "res3c_branch2c"
    name: "res3c_branch2c"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res3c_branch2c"
    top: "res3c_branch2c"
    name: "bn3c_branch2c"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res3c_branch2c"
    top: "res3c_branch2c"
    name: "scale3c_branch2c"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res3b"
    bottom: "res3c_branch2c"
    top: "res3c"
    name: "res3c"
    type: "Eltwise"
}

layer {
    bottom: "res3c"
    top: "res3c"
    name: "res3c_relu"
    type: "ReLU"
}

layer {
    bottom: "res3c"
    top: "res3d_branch2a"
    name: "res3d_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 128
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res3d_branch2a"
    top: "res3d_branch2a"
    name: "bn3d_branch2a"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res3d_branch2a"
    top: "res3d_branch2a"
    name: "scale3d_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res3d_branch2a"
    top: "res3d_branch2a"
    name: "res3d_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res3d_branch2a"
    top: "res3d_branch2b"
    name: "res3d_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 128
        kernel_size: 3
        pad: 1
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res3d_branch2b"
    top: "res3d_branch2b"
    name: "bn3d_branch2b"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res3d_branch2b"
    top: "res3d_branch2b"
    name: "scale3d_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res3d_branch2b"
    top: "res3d_branch2b"
    name: "res3d_branch2b_relu"
    type: "ReLU"
}

layer {
    bottom: "res3d_branch2b"
    top: "res3d_branch2c"
    name: "res3d_branch2c"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res3d_branch2c"
    top: "res3d_branch2c"
    name: "bn3d_branch2c"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res3d_branch2c"
    top: "res3d_branch2c"
    name: "scale3d_branch2c"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res3c"
    bottom: "res3d_branch2c"
    top: "res3d"
    name: "res3d"
    type: "Eltwise"
}

layer {
    bottom: "res3d"
    top: "res3d"
    name: "res3d_relu"
    type: "ReLU"
}

layer {
    bottom: "res3d"
    top: "res4a_branch1"
    name: "res4a_branch1"
    type: "Convolution"
    convolution_param {
        num_output: 1024
        kernel_size: 1
        pad: 0
        stride: 2
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res4a_branch1"
    top: "res4a_branch1"
    name: "bn4a_branch1"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4a_branch1"
    top: "res4a_branch1"
    name: "scale4a_branch1"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res3d"
    top: "res4a_branch2a"
    name: "res4a_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        pad: 0
        stride: 2
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res4a_branch2a"
    top: "res4a_branch2a"
    name: "bn4a_branch2a"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4a_branch2a"
    top: "res4a_branch2a"
    name: "scale4a_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4a_branch2a"
    top: "res4a_branch2a"
    name: "res4a_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res4a_branch2a"
    top: "res4a_branch2b"
    name: "res4a_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 3
        pad: 1
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res4a_branch2b"
    top: "res4a_branch2b"
    name: "bn4a_branch2b"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4a_branch2b"
    top: "res4a_branch2b"
    name: "scale4a_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4a_branch2b"
    top: "res4a_branch2b"
    name: "res4a_branch2b_relu"
    type: "ReLU"
}

layer {
    bottom: "res4a_branch2b"
    top: "res4a_branch2c"
    name: "res4a_branch2c"
    type: "Convolution"
    convolution_param {
        num_output: 1024
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res4a_branch2c"
    top: "res4a_branch2c"
    name: "bn4a_branch2c"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4a_branch2c"
    top: "res4a_branch2c"
    name: "scale4a_branch2c"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4a_branch1"
    bottom: "res4a_branch2c"
    top: "res4a"
    name: "res4a"
    type: "Eltwise"
}

layer {
    bottom: "res4a"
    top: "res4a"
    name: "res4a_relu"
    type: "ReLU"
}

layer {
    bottom: "res4a"
    top: "res4b_branch2a"
    name: "res4b_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res4b_branch2a"
    top: "res4b_branch2a"
    name: "bn4b_branch2a"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4b_branch2a"
    top: "res4b_branch2a"
    name: "scale4b_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4b_branch2a"
    top: "res4b_branch2a"
    name: "res4b_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res4b_branch2a"
    top: "res4b_branch2b"
    name: "res4b_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 3
        pad: 1
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res4b_branch2b"
    top: "res4b_branch2b"
    name: "bn4b_branch2b"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4b_branch2b"
    top: "res4b_branch2b"
    name: "scale4b_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4b_branch2b"
    top: "res4b_branch2b"
    name: "res4b_branch2b_relu"
    type: "ReLU"
}

layer {
    bottom: "res4b_branch2b"
    top: "res4b_branch2c"
    name: "res4b_branch2c"
    type: "Convolution"
    convolution_param {
        num_output: 1024
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res4b_branch2c"
    top: "res4b_branch2c"
    name: "bn4b_branch2c"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4b_branch2c"
    top: "res4b_branch2c"
    name: "scale4b_branch2c"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4a"
    bottom: "res4b_branch2c"
    top: "res4b"
    name: "res4b"
    type: "Eltwise"
}

layer {
    bottom: "res4b"
    top: "res4b"
    name: "res4b_relu"
    type: "ReLU"
}

layer {
    bottom: "res4b"
    top: "res4c_branch2a"
    name: "res4c_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res4c_branch2a"
    top: "res4c_branch2a"
    name: "bn4c_branch2a"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4c_branch2a"
    top: "res4c_branch2a"
    name: "scale4c_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4c_branch2a"
    top: "res4c_branch2a"
    name: "res4c_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res4c_branch2a"
    top: "res4c_branch2b"
    name: "res4c_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 3
        pad: 1
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res4c_branch2b"
    top: "res4c_branch2b"
    name: "bn4c_branch2b"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4c_branch2b"
    top: "res4c_branch2b"
    name: "scale4c_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4c_branch2b"
    top: "res4c_branch2b"
    name: "res4c_branch2b_relu"
    type: "ReLU"
}

layer {
    bottom: "res4c_branch2b"
    top: "res4c_branch2c"
    name: "res4c_branch2c"
    type: "Convolution"
    convolution_param {
        num_output: 1024
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res4c_branch2c"
    top: "res4c_branch2c"
    name: "bn4c_branch2c"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4c_branch2c"
    top: "res4c_branch2c"
    name: "scale4c_branch2c"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4b"
    bottom: "res4c_branch2c"
    top: "res4c"
    name: "res4c"
    type: "Eltwise"
}

layer {
    bottom: "res4c"
    top: "res4c"
    name: "res4c_relu"
    type: "ReLU"
}

layer {
    bottom: "res4c"
    top: "res4d_branch2a"
    name: "res4d_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res4d_branch2a"
    top: "res4d_branch2a"
    name: "bn4d_branch2a"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4d_branch2a"
    top: "res4d_branch2a"
    name: "scale4d_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4d_branch2a"
    top: "res4d_branch2a"
    name: "res4d_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res4d_branch2a"
    top: "res4d_branch2b"
    name: "res4d_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 3
        pad: 1
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res4d_branch2b"
    top: "res4d_branch2b"
    name: "bn4d_branch2b"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4d_branch2b"
    top: "res4d_branch2b"
    name: "scale4d_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4d_branch2b"
    top: "res4d_branch2b"
    name: "res4d_branch2b_relu"
    type: "ReLU"
}

layer {
    bottom: "res4d_branch2b"
    top: "res4d_branch2c"
    name: "res4d_branch2c"
    type: "Convolution"
    convolution_param {
        num_output: 1024
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res4d_branch2c"
    top: "res4d_branch2c"
    name: "bn4d_branch2c"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4d_branch2c"
    top: "res4d_branch2c"
    name: "scale4d_branch2c"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4c"
    bottom: "res4d_branch2c"
    top: "res4d"
    name: "res4d"
    type: "Eltwise"
}

layer {
    bottom: "res4d"
    top: "res4d"
    name: "res4d_relu"
    type: "ReLU"
}

layer {
    bottom: "res4d"
    top: "res4e_branch2a"
    name: "res4e_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res4e_branch2a"
    top: "res4e_branch2a"
    name: "bn4e_branch2a"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4e_branch2a"
    top: "res4e_branch2a"
    name: "scale4e_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4e_branch2a"
    top: "res4e_branch2a"
    name: "res4e_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res4e_branch2a"
    top: "res4e_branch2b"
    name: "res4e_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 3
        pad: 1
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res4e_branch2b"
    top: "res4e_branch2b"
    name: "bn4e_branch2b"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4e_branch2b"
    top: "res4e_branch2b"
    name: "scale4e_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4e_branch2b"
    top: "res4e_branch2b"
    name: "res4e_branch2b_relu"
    type: "ReLU"
}

layer {
    bottom: "res4e_branch2b"
    top: "res4e_branch2c"
    name: "res4e_branch2c"
    type: "Convolution"
    convolution_param {
        num_output: 1024
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res4e_branch2c"
    top: "res4e_branch2c"
    name: "bn4e_branch2c"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4e_branch2c"
    top: "res4e_branch2c"
    name: "scale4e_branch2c"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4d"
    bottom: "res4e_branch2c"
    top: "res4e"
    name: "res4e"
    type: "Eltwise"
}

layer {
    bottom: "res4e"
    top: "res4e"
    name: "res4e_relu"
    type: "ReLU"
}

layer {
    bottom: "res4e"
    top: "res4f_branch2a"
    name: "res4f_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res4f_branch2a"
    top: "res4f_branch2a"
    name: "bn4f_branch2a"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4f_branch2a"
    top: "res4f_branch2a"
    name: "scale4f_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4f_branch2a"
    top: "res4f_branch2a"
    name: "res4f_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res4f_branch2a"
    top: "res4f_branch2b"
    name: "res4f_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 3
        pad: 1
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res4f_branch2b"
    top: "res4f_branch2b"
    name: "bn4f_branch2b"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4f_branch2b"
    top: "res4f_branch2b"
    name: "scale4f_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4f_branch2b"
    top: "res4f_branch2b"
    name: "res4f_branch2b_relu"
    type: "ReLU"
}

layer {
    bottom: "res4f_branch2b"
    top: "res4f_branch2c"
    name: "res4f_branch2c"
    type: "Convolution"
    convolution_param {
        num_output: 1024
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res4f_branch2c"
    top: "res4f_branch2c"
    name: "bn4f_branch2c"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4f_branch2c"
    top: "res4f_branch2c"
    name: "scale4f_branch2c"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4e"
    bottom: "res4f_branch2c"
    top: "res4f"
    name: "res4f"
    type: "Eltwise"
}

layer {
    bottom: "res4f"
    top: "res4f"
    name: "res4f_relu"
    type: "ReLU"
}

layer {
    bottom: "res4f"
    top: "res5a_branch1"
    name: "res5a_branch1"
    type: "Convolution"
    convolution_param {
        num_output: 2048
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res5a_branch1"
    top: "res5a_branch1"
    name: "bn5a_branch1"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res5a_branch1"
    top: "res5a_branch1"
    name: "scale5a_branch1"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res4f"
    top: "res5a_branch2a"
    name: "res5a_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res5a_branch2a"
    top: "res5a_branch2a"
    name: "bn5a_branch2a"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res5a_branch2a"
    top: "res5a_branch2a"
    name: "scale5a_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res5a_branch2a"
    top: "res5a_branch2a"
    name: "res5a_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res5a_branch2a"
    top: "res5a_branch2b"
    name: "res5a_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 3
        dilation: 2
        pad: 2
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res5a_branch2b"
    top: "res5a_branch2b"
    name: "bn5a_branch2b"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res5a_branch2b"
    top: "res5a_branch2b"
    name: "scale5a_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res5a_branch2b"
    top: "res5a_branch2b"
    name: "res5a_branch2b_relu"
    type: "ReLU"
}

layer {
    bottom: "res5a_branch2b"
    top: "res5a_branch2c"
    name: "res5a_branch2c"
    type: "Convolution"
    convolution_param {
        num_output: 2048
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res5a_branch2c"
    top: "res5a_branch2c"
    name: "bn5a_branch2c"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res5a_branch2c"
    top: "res5a_branch2c"
    name: "scale5a_branch2c"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res5a_branch1"
    bottom: "res5a_branch2c"
    top: "res5a"
    name: "res5a"
    type: "Eltwise"
}

layer {
    bottom: "res5a"
    top: "res5a"
    name: "res5a_relu"
    type: "ReLU"
}

layer {
    bottom: "res5a"
    top: "res5b_branch2a"
    name: "res5b_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res5b_branch2a"
    top: "res5b_branch2a"
    name: "bn5b_branch2a"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res5b_branch2a"
    top: "res5b_branch2a"
    name: "scale5b_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res5b_branch2a"
    top: "res5b_branch2a"
    name: "res5b_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res5b_branch2a"
    top: "res5b_branch2b"
    name: "res5b_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 3
        dilation: 2
        pad: 2
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res5b_branch2b"
    top: "res5b_branch2b"
    name: "bn5b_branch2b"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res5b_branch2b"
    top: "res5b_branch2b"
    name: "scale5b_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res5b_branch2b"
    top: "res5b_branch2b"
    name: "res5b_branch2b_relu"
    type: "ReLU"
}

layer {
    bottom: "res5b_branch2b"
    top: "res5b_branch2c"
    name: "res5b_branch2c"
    type: "Convolution"
    convolution_param {
        num_output: 2048
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res5b_branch2c"
    top: "res5b_branch2c"
    name: "bn5b_branch2c"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res5b_branch2c"
    top: "res5b_branch2c"
    name: "scale5b_branch2c"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res5a"
    bottom: "res5b_branch2c"
    top: "res5b"
    name: "res5b"
    type: "Eltwise"
}

layer {
    bottom: "res5b"
    top: "res5b"
    name: "res5b_relu"
    type: "ReLU"
}

layer {
    bottom: "res5b"
    top: "res5c_branch2a"
    name: "res5c_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res5c_branch2a"
    top: "res5c_branch2a"
    name: "bn5c_branch2a"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res5c_branch2a"
    top: "res5c_branch2a"
    name: "scale5c_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res5c_branch2a"
    top: "res5c_branch2a"
    name: "res5c_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res5c_branch2a"
    top: "res5c_branch2b"
    name: "res5c_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 3
        dilation: 2
        pad: 2
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res5c_branch2b"
    top: "res5c_branch2b"
    name: "bn5c_branch2b"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res5c_branch2b"
    top: "res5c_branch2b"
    name: "scale5c_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res5c_branch2b"
    top: "res5c_branch2b"
    name: "res5c_branch2b_relu"
    type: "ReLU"
}

layer {
    bottom: "res5c_branch2b"
    top: "res5c_branch2c"
    name: "res5c_branch2c"
    type: "Convolution"
    convolution_param {
        num_output: 2048
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res5c_branch2c"
    top: "res5c_branch2c"
    name: "bn5c_branch2c"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res5c_branch2c"
    top: "res5c_branch2c"
    name: "scale5c_branch2c"
    type: "Scale"
    scale_param {
        bias_term: true
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
    param {
        lr_mult: 0.0
        decay_mult: 0.0
    }
}

layer {
    bottom: "res5b"
    bottom: "res5c_branch2c"
    top: "res5c"
    name: "res5c"
    type: "Eltwise"
}

layer {
    bottom: "res5c"
    top: "res5c"
    name: "res5c_relu"
    type: "ReLU"
}

#-------------------pos_mask residual------------------------------

layer {
    bottom: "res4f"
    top: "pos_mask_conv_1"
    name: "pos_mask_conv_1"
    type: "Convolution"
    convolution_param {
        num_output: 512 # K
        kernel_size: 3
        stride : 2
        pad: 1
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
        bias_filler {
            type: "constant"
            value: 0
        }
    }
    param {
        lr_mult: 1.0
    }
    param {
        lr_mult: 2.0
    }
}
layer {
    bottom: "pos_mask_conv_1"
    top: "pos_mask_conv_1"
    name: "pos_mask_conv_1_relu"
    type: "ReLU"
}




layer {
    bottom: "pos_mask_conv_1"
    top: "res_pos_mask1a_branch1"
    name: "res_pos_mask1a_branch1"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res_pos_mask1a_branch1"
    top: "res_pos_mask1a_branch1"
    name: "bn_pos_mask1a_branch1"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
}

layer {
    bottom: "res_pos_mask1a_branch1"
    top: "res_pos_mask1a_branch1"
    name: "scale_pos_mask1a_branch1"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "pos_mask_conv_1"
    top: "res_pos_mask1a_branch2a"
    name: "res_pos_mask1a_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res_pos_mask1a_branch2a"
    top: "res_pos_mask1a_branch2a"
    name: "bn_pos_mask1a_branch2a"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
}

layer {
    bottom: "res_pos_mask1a_branch2a"
    top: "res_pos_mask1a_branch2a"
    name: "scale_pos_mask1a_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res_pos_mask1a_branch2a"
    top: "res_pos_mask1a_branch2a"
    name: "res_pos_mask1a_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res_pos_mask1a_branch2a"
    top: "res_pos_mask1a_branch2b"
    name: "res_pos_mask1a_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 3
        dilation: 2
        pad: 2
        stride: 1
        bias_term: false
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res_pos_mask1a_branch2b"
    top: "res_pos_mask1a_branch2b"
    name: "bn_pos_mask1a_branch2b"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
}

layer {
    bottom: "res_pos_mask1a_branch2b"
    top: "res_pos_mask1a_branch2b"
    name: "scale_pos_mask1a_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res_pos_mask1a_branch2b"
    top: "res_pos_mask1a_branch2b"
    name: "res_pos_mask1a_branch2b_relu"
    type: "ReLU"
}

layer {
    bottom: "res_pos_mask1a_branch2b"
    top: "res_pos_mask1a_branch2c"
    name: "res_pos_mask1a_branch2c"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res_pos_mask1a_branch2c"
    top: "res_pos_mask1a_branch2c"
    name: "bn_pos_mask1a_branch2c"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
}

layer {
    bottom: "res_pos_mask1a_branch2c"
    top: "res_pos_mask1a_branch2c"
    name: "scale_pos_mask1a_branch2c"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res_pos_mask1a_branch1"
    bottom: "res_pos_mask1a_branch2c"
    top: "res_pos_mask1a"
    name: "res_pos_mask1a"
    type: "Eltwise"
}

layer {
    bottom: "res_pos_mask1a"
    top: "res_pos_mask1a"
    name: "res_pos_mask1a_relu"
    type: "ReLU"
}

layer {
    bottom: "res_pos_mask1a"
    top: "pos_mask_conv_2"
    name: "pos_mask_conv_2"
    type: "Convolution"
    convolution_param {
        num_output: 512 # K
        kernel_size: 3
        
        stride : 2
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
        bias_filler {
            type: "constant"
            value: 0
        }
    }
    param {
        lr_mult: 1.0
    }
    param {
        lr_mult: 2.0
    }
}


layer {
    bottom: "pos_mask_conv_2"
    top: "pos_mask_conv_2"
    name: "pos_mask_conv_2_relu"
    type: "ReLU"
}




layer {
    bottom: "pos_mask_conv_2"
    top: "res_pos_mask1b_branch1"
    name: "res_pos_mask1b_branch1"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res_pos_mask1b_branch1"
    top: "res_pos_mask1b_branch1"
    name: "bn_pos_mask1b_branch1"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
}

layer {
    bottom: "res_pos_mask1b_branch1"
    top: "res_pos_mask1b_branch1"
    name: "scale_pos_mask1b_branch1"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "pos_mask_conv_2"
    top: "res_pos_mask1b_branch2a"
    name: "res_pos_mask1b_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res_pos_mask1b_branch2a"
    top: "res_pos_mask1b_branch2a"
    name: "bn_pos_mask1b_branch2a"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
}

layer {
    bottom: "res_pos_mask1b_branch2a"
    top: "res_pos_mask1b_branch2a"
    name: "scale_pos_mask1b_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res_pos_mask1b_branch2a"
    top: "res_pos_mask1b_branch2a"
    name: "res_pos_mask1b_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res_pos_mask1b_branch2a"
    top: "res_pos_mask1b_branch2b"
    name: "res_pos_mask1b_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 3
        dilation: 2
        pad: 2
        stride: 1
        bias_term: false
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res_pos_mask1b_branch2b"
    top: "res_pos_mask1b_branch2b"
    name: "bn_pos_mask1b_branch2b"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
}

layer {
    bottom: "res_pos_mask1b_branch2b"
    top: "res_pos_mask1b_branch2b"
    name: "scale_pos_mask1b_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res_pos_mask1b_branch2b"
    top: "res_pos_mask1b_branch2b"
    name: "res_pos_mask1b_branch2b_relu"
    type: "ReLU"
}

layer {
    bottom: "res_pos_mask1b_branch2b"
    top: "res_pos_mask1b_branch2c"
    name: "res_pos_mask1b_branch2c"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res_pos_mask1b_branch2c"
    top: "res_pos_mask1b_branch2c"
    name: "bn_pos_mask1b_branch2c"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
}

layer {
    bottom: "res_pos_mask1b_branch2c"
    top: "res_pos_mask1b_branch2c"
    name: "scale_pos_mask1b_branch2c"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res_pos_mask1b_branch1"
    bottom: "res_pos_mask1b_branch2c"
    top: "res_pos_mask1b"
    name: "res_pos_mask1b"
    type: "Eltwise"
}

layer {
    bottom: "res_pos_mask1b"
    top: "res_pos_mask1b"
    name: "res_pos_mask1b_relu"
    type: "ReLU"
}



layer {
    bottom: "res_pos_mask1b"
    top: "pos_mask_deconv_1"
    name: "pos_mask_deconv_1"
    type: "Deconvolution"
    convolution_param {
        num_output: 512 # K
        kernel_size: 3
      
        stride : 2
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
        bias_filler {
            type: "constant"
            value: 0
        }
    }
    param {
        lr_mult: 1.0
    }
    param {
        lr_mult: 2.0
    }
}
layer {
    bottom: "pos_mask_deconv_1"
    top: "pos_mask_deconv_1"
    name: "pos_mask_deconv_1_relu"
    type: "ReLU"
}


layer {
    bottom: "pos_mask_deconv_1"
    top: "res_pos_mask1c_branch1"
    name: "res_pos_mask1c_branch1"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res_pos_mask1c_branch1"
    top: "res_pos_mask1c_branch1"
    name: "bn_pos_mask1c_branch1"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
}

layer {
    bottom: "res_pos_mask1c_branch1"
    top: "res_pos_mask1c_branch1"
    name: "scale_pos_mask1c_branch1"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "pos_mask_deconv_1"
    top: "res_pos_mask1c_branch2a"
    name: "res_pos_mask1c_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res_pos_mask1c_branch2a"
    top: "res_pos_mask1c_branch2a"
    name: "bn_pos_mask1c_branch2a"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
}

layer {
    bottom: "res_pos_mask1c_branch2a"
    top: "res_pos_mask1c_branch2a"
    name: "scale_pos_mask1c_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res_pos_mask1c_branch2a"
    top: "res_pos_mask1c_branch2a"
    name: "res_pos_mask1c_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res_pos_mask1c_branch2a"
    top: "res_pos_mask1c_branch2b"
    name: "res_pos_mask1c_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 3
        dilation: 2
        pad: 2
        stride: 1
        bias_term: false
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res_pos_mask1c_branch2b"
    top: "res_pos_mask1c_branch2b"
    name: "bn_pos_mask1c_branch2b"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
}

layer {
    bottom: "res_pos_mask1c_branch2b"
    top: "res_pos_mask1c_branch2b"
    name: "scale_pos_mask1c_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res_pos_mask1c_branch2b"
    top: "res_pos_mask1c_branch2b"
    name: "res_pos_mask1c_branch2b_relu"
    type: "ReLU"
}

layer {
    bottom: "res_pos_mask1c_branch2b"
    top: "res_pos_mask1c_branch2c"
    name: "res_pos_mask1c_branch2c"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res_pos_mask1c_branch2c"
    top: "res_pos_mask1c_branch2c"
    name: "bn_pos_mask1c_branch2c"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
}

layer {
    bottom: "res_pos_mask1c_branch2c"
    top: "res_pos_mask1c_branch2c"
    name: "scale_pos_mask1c_branch2c"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res_pos_mask1c_branch1"
    bottom: "res_pos_mask1c_branch2c"
    top: "res_pos_mask1c"
    name: "res_pos_mask1c"
    type: "Eltwise"
}

layer {
    bottom: "res_pos_mask1c"
    top: "res_pos_mask1c"
    name: "res_pos_mask1c_relu"
    type: "ReLU"
}





layer {
    bottom: "res_pos_mask1c"
    top: "pos_mask_deconv_2"
    name: "pos_mask_deconv_2"
    type: "Deconvolution"
    convolution_param {
        num_output: 25 # K * 2
        kernel_size: 3
        stride : 2
        pad:0
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
        bias_filler {
            type: "constant"
            value: 0
        }
    }
    param {
        lr_mult: 1.0
    }
    param {
        lr_mult: 2.0
    }
}

layer {
    bottom: "pos_mask_deconv_2"
    top: "pos_mask_deconv_2"
    name: "bn_pos_mask_deconv_2"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
}

layer {
    bottom: "pos_mask_deconv_2"
    top: "pos_mask_deconv_2"
    name: "scale_pos_mask_deconv_2"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    name:"Sig_pos_mask"
    bottom:"pos_mask_deconv_2"
    top:"Sig_pos_mask"
    type:"Sigmoid"

}



#-------------------neg_mask residual------------------------------

layer {
    bottom: "res4f"
    top: "neg_mask_conv_1"
    name: "neg_mask_conv_1"
    type: "Convolution"
    convolution_param {
        num_output: 512 # K
        kernel_size: 3
        stride : 2
        
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
        bias_filler {
            type: "constant"
            value: 0
        }
    }
    param {
        lr_mult: 1.0
    }
    param {
        lr_mult: 2.0
    }
}
layer {
    bottom: "neg_mask_conv_1"
    top: "neg_mask_conv_1"
    name: "neg_mask_conv_1_relu"
    type: "ReLU"
}




layer {
    bottom: "neg_mask_conv_1"
    top: "res_neg_mask1a_branch1"
    name: "res_neg_mask1a_branch1"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res_neg_mask1a_branch1"
    top: "res_neg_mask1a_branch1"
    name: "bn_neg_mask1a_branch1"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
}

layer {
    bottom: "res_neg_mask1a_branch1"
    top: "res_neg_mask1a_branch1"
    name: "scale_neg_mask1a_branch1"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "neg_mask_conv_1"
    top: "res_neg_mask1a_branch2a"
    name: "res_neg_mask1a_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res_neg_mask1a_branch2a"
    top: "res_neg_mask1a_branch2a"
    name: "bn_neg_mask1a_branch2a"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
}

layer {
    bottom: "res_neg_mask1a_branch2a"
    top: "res_neg_mask1a_branch2a"
    name: "scale_neg_mask1a_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res_neg_mask1a_branch2a"
    top: "res_neg_mask1a_branch2a"
    name: "res_neg_mask1a_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res_neg_mask1a_branch2a"
    top: "res_neg_mask1a_branch2b"
    name: "res_neg_mask1a_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 3
        dilation: 2
        pad: 2
        stride: 1
        bias_term: false
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res_neg_mask1a_branch2b"
    top: "res_neg_mask1a_branch2b"
    name: "bn_neg_mask1a_branch2b"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
}

layer {
    bottom: "res_neg_mask1a_branch2b"
    top: "res_neg_mask1a_branch2b"
    name: "scale_neg_mask1a_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res_neg_mask1a_branch2b"
    top: "res_neg_mask1a_branch2b"
    name: "res_neg_mask1a_branch2b_relu"
    type: "ReLU"
}

layer {
    bottom: "res_neg_mask1a_branch2b"
    top: "res_neg_mask1a_branch2c"
    name: "res_neg_mask1a_branch2c"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res_neg_mask1a_branch2c"
    top: "res_neg_mask1a_branch2c"
    name: "bn_neg_mask1a_branch2c"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
}

layer {
    bottom: "res_neg_mask1a_branch2c"
    top: "res_neg_mask1a_branch2c"
    name: "scale_neg_mask1a_branch2c"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res_neg_mask1a_branch1"
    bottom: "res_neg_mask1a_branch2c"
    top: "res_neg_mask1a"
    name: "res_neg_mask1a"
    type: "Eltwise"
}

layer {
    bottom: "res_neg_mask1a"
    top: "res_neg_mask1a"
    name: "res_neg_mask1a_relu"
    type: "ReLU"
}

layer {
    bottom: "res_neg_mask1a"
    top: "neg_mask_conv_2"
    name: "neg_mask_conv_2"
    type: "Convolution"
    convolution_param {
        num_output: 512 # K
        kernel_size: 3
        
        stride : 2
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
        bias_filler {
            type: "constant"
            value: 0
        }
    }
    param {
        lr_mult: 1.0
    }
    param {
        lr_mult: 2.0
    }
}


layer {
    bottom: "neg_mask_conv_2"
    top: "neg_mask_conv_2"
    name: "neg_mask_conv_2_relu"
    type: "ReLU"
}




layer {
    bottom: "neg_mask_conv_2"
    top: "res_neg_mask1b_branch1"
    name: "res_neg_mask1b_branch1"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res_neg_mask1b_branch1"
    top: "res_neg_mask1b_branch1"
    name: "bn_neg_mask1b_branch1"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
}

layer {
    bottom: "res_neg_mask1b_branch1"
    top: "res_neg_mask1b_branch1"
    name: "scale_neg_mask1b_branch1"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "neg_mask_conv_2"
    top: "res_neg_mask1b_branch2a"
    name: "res_neg_mask1b_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res_neg_mask1b_branch2a"
    top: "res_neg_mask1b_branch2a"
    name: "bn_neg_mask1b_branch2a"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
}

layer {
    bottom: "res_neg_mask1b_branch2a"
    top: "res_neg_mask1b_branch2a"
    name: "scale_neg_mask1b_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res_neg_mask1b_branch2a"
    top: "res_neg_mask1b_branch2a"
    name: "res_neg_mask1b_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res_neg_mask1b_branch2a"
    top: "res_neg_mask1b_branch2b"
    name: "res_neg_mask1b_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 3
        dilation: 2
        pad: 2
        stride: 1
        bias_term: false
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res_neg_mask1b_branch2b"
    top: "res_neg_mask1b_branch2b"
    name: "bn_neg_mask1b_branch2b"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
}

layer {
    bottom: "res_neg_mask1b_branch2b"
    top: "res_neg_mask1b_branch2b"
    name: "scale_neg_mask1b_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res_neg_mask1b_branch2b"
    top: "res_neg_mask1b_branch2b"
    name: "res_neg_mask1b_branch2b_relu"
    type: "ReLU"
}

layer {
    bottom: "res_neg_mask1b_branch2b"
    top: "res_neg_mask1b_branch2c"
    name: "res_neg_mask1b_branch2c"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res_neg_mask1b_branch2c"
    top: "res_neg_mask1b_branch2c"
    name: "bn_neg_mask1b_branch2c"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
}

layer {
    bottom: "res_neg_mask1b_branch2c"
    top: "res_neg_mask1b_branch2c"
    name: "scale_neg_mask1b_branch2c"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res_neg_mask1b_branch1"
    bottom: "res_neg_mask1b_branch2c"
    top: "res_neg_mask1b"
    name: "res_neg_mask1b"
    type: "Eltwise"
}

layer {
    bottom: "res_neg_mask1b"
    top: "res_neg_mask1b"
    name: "res_neg_mask1b_relu"
    type: "ReLU"
}



layer {
    bottom: "res_neg_mask1b"
    top: "neg_mask_deconv_1"
    name: "neg_mask_deconv_1"
    type: "Deconvolution"
    convolution_param {
        num_output: 512 # K
        kernel_size: 3
      
        stride : 2
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
        bias_filler {
            type: "constant"
            value: 0
        }
    }
    param {
        lr_mult: 1.0
    }
    param {
        lr_mult: 2.0
    }
}
layer {
    bottom: "neg_mask_deconv_1"
    top: "neg_mask_deconv_1"
    name: "neg_mask_deconv_1_relu"
    type: "ReLU"
}


layer {
    bottom: "neg_mask_deconv_1"
    top: "res_neg_mask1c_branch1"
    name: "res_neg_mask1c_branch1"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res_neg_mask1c_branch1"
    top: "res_neg_mask1c_branch1"
    name: "bn_neg_mask1c_branch1"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
}

layer {
    bottom: "res_neg_mask1c_branch1"
    top: "res_neg_mask1c_branch1"
    name: "scale_neg_mask1c_branch1"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "neg_mask_deconv_1"
    top: "res_neg_mask1c_branch2a"
    name: "res_neg_mask1c_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res_neg_mask1c_branch2a"
    top: "res_neg_mask1c_branch2a"
    name: "bn_neg_mask1c_branch2a"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
}

layer {
    bottom: "res_neg_mask1c_branch2a"
    top: "res_neg_mask1c_branch2a"
    name: "scale_neg_mask1c_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res_neg_mask1c_branch2a"
    top: "res_neg_mask1c_branch2a"
    name: "res_neg_mask1c_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res_neg_mask1c_branch2a"
    top: "res_neg_mask1c_branch2b"
    name: "res_neg_mask1c_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 3
        dilation: 2
        pad: 2
        stride: 1
        bias_term: false
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res_neg_mask1c_branch2b"
    top: "res_neg_mask1c_branch2b"
    name: "bn_neg_mask1c_branch2b"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
}

layer {
    bottom: "res_neg_mask1c_branch2b"
    top: "res_neg_mask1c_branch2b"
    name: "scale_neg_mask1c_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res_neg_mask1c_branch2b"
    top: "res_neg_mask1c_branch2b"
    name: "res_neg_mask1c_branch2b_relu"
    type: "ReLU"
}

layer {
    bottom: "res_neg_mask1c_branch2b"
    top: "res_neg_mask1c_branch2c"
    name: "res_neg_mask1c_branch2c"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        pad: 0
        stride: 1
        bias_term: false
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
    }
    param {
        lr_mult: 1.0
    }
}

layer {
    bottom: "res_neg_mask1c_branch2c"
    top: "res_neg_mask1c_branch2c"
    name: "bn_neg_mask1c_branch2c"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
}

layer {
    bottom: "res_neg_mask1c_branch2c"
    top: "res_neg_mask1c_branch2c"
    name: "scale_neg_mask1c_branch2c"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res_neg_mask1c_branch1"
    bottom: "res_neg_mask1c_branch2c"
    top: "res_neg_mask1c"
    name: "res_neg_mask1c"
    type: "Eltwise"
}

layer {
    bottom: "res_neg_mask1c"
    top: "res_neg_mask1c"
    name: "res_neg_mask1c_relu"
    type: "ReLU"
}





layer {
    bottom: "res_neg_mask1c"
    top: "neg_mask_deconv_2"
    name: "neg_mask_deconv_2"
    type: "Deconvolution"
    convolution_param {
        num_output: 25 # K * 2
        kernel_size: 3
        stride : 2
        
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
        bias_filler {
            type: "constant"
            value: 0
        }
    }
    param {
        lr_mult: 1.0
    }
    param {
        lr_mult: 2.0
    }
}

layer {
    bottom: "neg_mask_deconv_2"
    top: "neg_mask_deconv_2"
    name: "bn_neg_mask_deconv_2"
    type: "BatchNorm"
    batch_norm_param {
        use_global_stats: false
    }
}

layer {
    bottom: "neg_mask_deconv_2"
    top: "neg_mask_deconv_2"
    name: "scale_neg_mask_deconv_2"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    name:"Sig_neg_mask"
    bottom:"neg_mask_deconv_2"
    top:"Sig_neg_mask"
    type:"Sigmoid"

}

#----------------------new conv layer------------------
layer {
    bottom: "res5c"
    top: "conv_new_1"
    name: "conv_new_1"
    type: "Convolution"
    convolution_param {
        num_output: 1024
        kernel_size: 1
        pad: 0
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
        bias_filler {
            type: "constant"
            value: 0
        }
    }
    param {
        lr_mult: 1.0
    }
    param {
        lr_mult: 2.0
    }
}

layer {
    bottom: "conv_new_1"
    top: "conv_new_1"
    name: "conv_new_1_relu"
    type: "ReLU"
}

layer {
    bottom: "conv_new_1"
    top: "rfcn_pos_cls_soft"
    name: "rfcn_pos_cls_soft"
    type: "Convolution"
    convolution_param {
        num_output: 500 # cls_num( 4 )*K(25)
        kernel_size: 1
        pad: 0
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
        bias_filler {
            type: "constant"
            value: 0
        }
    }
    param {
        lr_mult: 1.0
    }
    param {
        lr_mult: 2.0
    }
}

layer {
    bottom: "conv_new_1"
    top: "rfcn_pos_bbox_soft"
    name: "rfcn_pos_bbox_soft"
    type: "Convolution"
    convolution_param {
        num_output: 100 #8*4   4*(1 + 1)*K
        kernel_size: 1
        pad: 0
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
        bias_filler {
            type: "constant"
            value: 0
        }
    }
    param {
        lr_mult: 1.0
    }
    param {
        lr_mult: 2.0
    }
}

layer {
    bottom: "conv_new_1"
    top: "rfcn_neg_bbox_soft"
    name: "rfcn_neg_bbox_soft"
    type: "Convolution"
    convolution_param {
        num_output: 100 #8*4   4*(1 + 1)*K
        kernel_size: 1
        pad: 0
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
        bias_filler {
            type: "constant"
            value: 0
        }
    }
    param {
        lr_mult: 1.0
    }
    param {
        lr_mult: 2.0
    }
}

layer {
  name: "roi_pool_neg_bbox"
  type: "ROIPooling"
  bottom: "rfcn_neg_bbox_soft"
  bottom: "rois"
  top: "roi_pool_neg_bbox"
  roi_pooling_param {
    pooled_w: 15
    pooled_h: 15
    spatial_scale: 0.0625 # 1/16
  }
}

layer {
  name: "roi_pool_pos_bbox"
  type: "ROIPooling"
  bottom: "rfcn_pos_bbox_soft"
  bottom: "rois"
  top: "roi_pool_pos_bbox"
  roi_pooling_param {
    pooled_w: 15
    pooled_h: 15
    spatial_scale: 0.0625 # 1/16
  }
}


layer {
  name: "roi_pool_pos_cls"
  type: "ROIPooling"
  bottom: "rfcn_pos_cls_soft"
  bottom: "rois"
  top: "roi_pool_pos_cls"
  roi_pooling_param {
    pooled_w: 15
    pooled_h: 15
    spatial_scale: 0.0625 # 1/16
  }
}

layer {
  name: "roi_pool_pos_mask"
  type: "ROIPooling"
  bottom: "Sig_pos_mask"
  bottom: "rois"
  top: "roi_pool_pos_mask"
  roi_pooling_param {
    pooled_w: 15
    pooled_h: 15
    spatial_scale: 0.0625 # 1/16
  }
}

layer {
  name: "roi_pool_neg_mask"
  type: "ROIPooling"
  bottom: "Sig_neg_mask"
  bottom: "rois"
  top: "roi_pool_neg_mask"
  roi_pooling_param {
    pooled_w: 15
    pooled_h: 15
    spatial_scale: 0.0625 # 1/16
  }
}


#-------------------------deterministic module -----------------------------

layer{
    name:"determinstic_concat"
    bottom:"roi_pool_pos_cls"
    bottom:"roi_pool_pos_mask"
    bottom:"roi_pool_neg_mask"
    top:"determinstic_concat"
    type:"Concat"
}

layer:{
    name:"determinstic_relu"
    bottom:"determinstic_concat"
    top:"determinstic_concat"
    type:"ReLU"

}


layer {
    bottom: "determinstic_concat"
    top: "determinstic_conv1"
    name: "determinstic_conv1"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 3
        dilation: 2
        pad: 2
        stride: 1
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
    }
    param {
        lr_mult: 1.0
    }
}

layer:{
    name:"determinstic_conv1_relu"
    bottom:"determinstic_conv1"
    top:"determinstic_conv1"
    type:"ReLU"

}
layer {
    bottom: "determinstic_conv1"
    top: "determinstic_conv2"
    name: "determinstic_conv2"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 3
        dilation: 2
        pad: 2
        stride: 1
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
    }
    param {
        lr_mult: 1.0
    }
}
layer:{
    name:"determinstic_conv2_relu"
    bottom:"determinstic_conv2"
    top:"determinstic_conv2"
    type:"ReLU"

}
layer {
    bottom: "determinstic_conv2"
    top: "determinstic_conv3"
    name: "determinstic_conv3"
    type: "Convolution"
    convolution_param {
        num_output: 2
        kernel_size: 3
        dilation: 2
        pad: 2
        stride: 1
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
    }
    param {
        lr_mult: 1.0
    }
}

layer{
    name:"deterministic"
    bottom:"determinstic_conv3"
    type:"Pooling"
    top:"deterministic"
    pooling_param {
        kernel_size: 15
        stride: 1
        pool: AVE
    }
}

layer{
    name:"deterministic_prob"
    bottom:"deterministic"
    top:"deterministic_prob"
    type:"Softmax"
}

layer{
    name:"deterministic_prob_slice"
    bottom:"deterministic_prob"
    top:"neg_prob"
    top:"pos_prob"
    type:"Slice"
    slice_param{
        slice_point: 1
    }
}




#--------------soft RoI pooling------------------
layer {
    bottom: "roi_pool_pos_mask"
    top: "roi_pool_pos_mask_tile"
    name: "roi_pool_pos_mask_tile"
    type: "Tile"
    tile_param {
        tiles : 20
    }
}

layer  {
    bottom:"roi_pool_pos_mask_tile"
    bottom:"roi_pool_pos_cls"
    top:"pos_cls_assemble_1"
    name:"pos_cls_assemble_1"
    type:"Eltwise"
    eltwise_param{
    operation : PROD
    }
}

layer  {
    bottom:"pos_cls_assemble_1"
    bottom:"roi_pool_pos_cls"
    top:"pos_cls_assemble"
    name:"pos_cls_assemble"
    type:"Eltwise"
    eltwise_param{
    operation : SUM
    }
}


layer  {
    bottom:"pos_cls_assemble"
    top:"pos_cls_reshape"
    type:"Reshape"
    name:"pos_cls_reshape"
    reshape_param{shape { dim:  0  dim:  20 dim: 25 dim: 225}} #21, K
}

layer{

bottom:"pos_cls_reshape"
top:"pos_cls_score"
name:"pos_cls_pool"
type:"Pooling"
  pooling_param {
    pool: AVE
    kernel_h: 25
    kernel_w: 225  #K
    stride: 1
  }

}

layer {
    
    bottom: "roi_pool_pos_mask"
    top: "roi_pool_pos_mask_tile_bbox"
    name: "roi_pool_pos_mask_tile_bbox"
    type: "Tile"
    tile_param {
        tiles : 4
    }
}

layer  {
    bottom:"roi_pool_pos_mask_tile_bbox"
    bottom:"roi_pool_pos_bbox"
    top:"pos_bbox_assemble_1"
    name:"pos_bbox_assemble_1"
    type:"Eltwise"
    eltwise_param{
    operation : PROD
    }
}

layer  {
    bottom:"pos_bbox_assemble_1"
    bottom:"roi_pool_pos_bbox"
    top:"pos_bbox_assemble"
    name:"pos_bbox_assemble"
    type:"Eltwise"
    eltwise_param{
    operation : SUM
    }
}



layer  {
    bottom:"pos_bbox_assemble"
    top:"pos_bbox_reshape"
    type:"Reshape"
    name:"pos_bbox_reshape"
    reshape_param{shape { dim:  0  dim:  4 dim: 25 dim: 225}} #21, K
}

layer{

bottom:"pos_bbox_reshape"
top:"pos_bbox_pred"
name:"pos_bbox_pool"
type:"Pooling"
  pooling_param {
    pool: AVE
    kernel_h: 25
    kernel_w: 225  #K
    stride: 1
  }

}

layer {
    bottom: "roi_pool_neg_mask"
    top: "roi_pool_neg_mask_tile"
    name: "roi_pool_neg_mask_tile"
    type: "Tile"
    tile_param {
        tiles : 20
    }
}

layer  {
    bottom:"roi_pool_neg_mask_tile"
    bottom:"roi_pool_pos_cls"
    top:"neg_cls_assemble_1"
    name:"neg_cls_assemble_1"
    type:"Eltwise"
    eltwise_param{
    operation : PROD
    }
}

layer  {
    bottom:"neg_cls_assemble_1"
    bottom:"roi_pool_pos_cls"
    top:"neg_cls_assemble"
    name:"neg_cls_assemble"
    type:"Eltwise"
    eltwise_param{
    operation : SUM
    }
}


layer  {
    bottom:"neg_cls_assemble"
    top:"neg_cls_reshape"
    type:"Reshape"
    name:"neg_cls_reshape"
    reshape_param{shape { dim:  0  dim:  1 dim: 500 dim: 225}} #21, K
}

layer{

bottom:"neg_cls_reshape"
top:"neg_cls_score"
name:"neg_cls_pool"
type:"Pooling"
  pooling_param {
    pool: AVE
    kernel_h: 500
    kernel_w: 225  #K
    stride: 1
  }

}

layer {
    
    bottom: "roi_pool_neg_mask"
    top: "roi_pool_neg_bbox_tile"
    name: "roi_pool_neg_bbox_tile"
    type: "Tile"
    tile_param {
        tiles : 4
    }
}

layer  {
    bottom:"roi_pool_neg_bbox_tile"
    bottom:"roi_pool_neg_bbox"
    top:"neg_bbox_assemble_1"
    name:"neg_bbox_assemble_1"
    type:"Eltwise"
    eltwise_param{
    operation : PROD
    }
}

layer  {
    bottom:"neg_bbox_assemble_1"
    bottom:"roi_pool_neg_bbox"
    top:"neg_bbox_assemble"
    name:"neg_bbox_assemble"
    type:"Eltwise"
    eltwise_param{
    operation : SUM
    }
}



layer  {
    bottom:"neg_bbox_assemble"
    top:"neg_bbox_reshape"
    type:"Reshape"
    name:"neg_bbox_reshape"
    reshape_param{shape { dim:  0  dim:  4 dim: 25 dim: 225}} #21, K
}

layer{

bottom:"neg_bbox_reshape"
top:"neg_bbox_pred"
name:"neg_bbox_pool"
type:"Pooling"
  pooling_param {
    pool: AVE
    kernel_h: 25
    kernel_w: 225  #K
    stride: 1
  }

}


layer {
    
    bottom: "neg_prob"
    top: "neg_prob_tile"
    name: "neg_prob_tile"
    type: "Tile"
    tile_param {
        tiles : 1
    }
}
layer {
    
    bottom: "pos_prob"
    top: "pos_prob_tile"
    name: "pos_prob_tile"
    type: "Tile"
    tile_param {
        tiles : 20
    }
}
layer{
    name:"pos_cls_prob_apply"
    bottom:"pos_cls_score"
    bottom:"pos_prob_tile"
    top:"pos_cls_score_apply"
    type:"Eltwise"
    eltwise_param{
      operation : PROD
    }

}
layer{
    name:"neg_cls_prob_apply"
    bottom:"neg_cls_score"
    bottom:"neg_prob_tile"
    top:"neg_cls_score_apply"
    type:"Eltwise"
    eltwise_param{
      operation : PROD
    }

}


layer{
    name:"cls_score_concat"
    bottom:"neg_cls_score_apply"
    bottom:"pos_cls_score_apply"
    top:"cls_score"
    type:"Concat"
}

layer{
    name:"bbox_pred_concat"
    bottom:"neg_bbox_pred"
    bottom:"pos_bbox_pred"
    top:"bbox_pred"
    type:"Concat"
}


#--------------online hard example mining--------------
layer {
   name: "per_roi_loss_cls"
   type: "SoftmaxWithLossOHEM"
   bottom: "cls_score"
   bottom: "labels"
   top: "temp_loss_cls"
   top: "temp_prob_cls"
   top: "per_roi_loss_cls"
   loss_weight: 0
   loss_weight: 0
   loss_weight: 0
   softmax_param {
       axis : 1
   }
   propagate_down: false
   propagate_down: false
}

layer {
   name: "per_roi_loss_deterministic"
   type: "SoftmaxWithLossOHEM"
   bottom: "deterministic"
   bottom: "Sig_rfcn_mask_label"
   top: "temp_loss_deterministic"
   top: "temp_prob_deterministic"
   top: "per_roi_loss_deterministic"
   loss_weight: 0
   loss_weight: 0
   loss_weight: 0
   softmax_param {
       axis : 1
   }
   propagate_down: false
   propagate_down: false
}

layer {
   name: "per_roi_loss_bbox"
   type: "SmoothL1LossOHEM"
   bottom: "bbox_pred"
   bottom: "bbox_targets"
   bottom: "bbox_inside_weights"
   top: "temp_loss_bbox"
   top: "per_roi_loss_bbox"
   loss_weight: 0
   loss_weight: 0
   propagate_down: false
   propagate_down: false
   propagate_down: false
}

layer {
   name: "per_roi_loss"
   type: "Eltwise"
   bottom: "per_roi_loss_cls"
   bottom: "per_roi_loss_bbox"
   bottom:"per_roi_loss_deterministic"
   top: "per_roi_loss"
   propagate_down: false
   propagate_down: false
   propagate_down: false
   eltwise_param{
   coeff:1
   coeff:1
   coeff:5
   }





}

layer {
   bottom: "rois"
   bottom: "per_roi_loss"
   bottom: "labels"
   bottom: "bbox_inside_weights"
   top: "labels_ohem"
   top: "bbox_loss_weights_ohem"
   name: "annotator_detector"
   type: "BoxAnnotatorOHEM"
   box_annotator_ohem_param {
        roi_per_img: 128
        ignore_label: -1
   }
   propagate_down: false
   propagate_down: false
   propagate_down: false
   propagate_down: false
}

layer {
   bottom: "rois"
   bottom: "per_roi_loss"
   bottom: "Sig_rfcn_mask_label"
   bottom: "bbox_inside_weights"
   top: "labels_deterministic_ohem"
   top: "bbox_loss_weights_deterministic_ohem"
   name: "annotator_detector_deterministic"
   type: "BoxAnnotatorOHEM"
   box_annotator_ohem_param {
        roi_per_img: 128
        ignore_label: -1
   }
   propagate_down: false
   propagate_down: false
   propagate_down: false
   propagate_down: false
}

layer {
   name: "silence"
   type: "Silence"
   bottom: "bbox_outside_weights"
   bottom: "temp_loss_cls"
   bottom: "temp_prob_cls"
   bottom: "temp_loss_bbox"
   bottom: "foreverone"
   bottom: "temp_loss_deterministic"
   bottom: "temp_prob_deterministic"
   bottom: "bbox_loss_weights_deterministic_ohem"
}

#-----------------------output------------------------
layer {
   name: "loss"
   type: "SoftmaxWithLoss"
   bottom: "cls_score"
   bottom: "labels_ohem"
   top: "loss_cls"
   loss_weight: 1
   softmax_param{
       axis : 1
   }
   loss_param {
        ignore_label: -1
   }
   propagate_down: true
   propagate_down: false
}

layer {
   name: "loss_deterministic"
   type: "SoftmaxWithLoss"
   bottom: "deterministic"
   bottom: "labels_deterministic_ohem"
   top: "loss_deterministic"
   loss_weight: 5
   softmax_param{
       axis : 1
   }
   loss_param {
        ignore_label: -1
   }
   propagate_down: true
   propagate_down: false
}

layer {
   name: "accuarcy"
   type: "Accuracy"
   bottom: "cls_score"
   bottom: "labels_ohem"
   top: "accuarcy"
   #include: { phase: TEST }
   accuracy_param {
        ignore_label: -1
        axis : 1
   }
   propagate_down: false
   propagate_down: false
}

layer {
   name: "loss_bbox"
   type: "SmoothL1LossOHEM"
   bottom: "bbox_pred"
   bottom: "bbox_targets"
   bottom: "bbox_loss_weights_ohem"
   top: "loss_bbox"
   loss_weight: 1
   loss_param {
        normalization: PRE_FIXED
        pre_fixed_normalizer: 128
   }
   propagate_down: true
   propagate_down: false
   propagate_down: false
}
  
